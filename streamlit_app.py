"""
Streamlit UI Application - ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ìƒì„± ì¸í„°í˜ì´ìŠ¤

ì‚¬ìš©ìê°€ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ì»¤ë°‹ì„ ì„ íƒí•˜ê³ , ë‹¨ê³„ë³„ë¡œ í…ŒìŠ¤íŠ¸ ìƒì„± ê³¼ì •ì„ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆëŠ” UIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""
import asyncio
import json
import os
import tempfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from streamlit_option_menu import option_menu

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
import sys
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.ai_test_generator.core.commit_selector import CommitSelector, CommitInfo
from src.ai_test_generator.core.pipeline_stages import (
    PipelineOrchestrator, PipelineContext, PipelineStage, StageStatus
)
from src.ai_test_generator.utils.config import Config
from src.ai_test_generator.utils.logger import setup_logger, get_logger

# ë¡œê±° ì´ˆê¸°í™”
setup_logger('INFO')
logger = get_logger(__name__)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI í…ŒìŠ¤íŠ¸ ìƒì„±ê¸°",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
def init_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'config' not in st.session_state:
        st.session_state.config = Config()
    
    if 'commit_selector' not in st.session_state:
        st.session_state.commit_selector = None
    
    if 'pipeline_orchestrator' not in st.session_state:
        st.session_state.pipeline_orchestrator = None
    
    if 'pipeline_context' not in st.session_state:
        st.session_state.pipeline_context = None
    
    if 'pipeline_results' not in st.session_state:
        st.session_state.pipeline_results = {}
    
    if 'selected_commits' not in st.session_state:
        st.session_state.selected_commits = []
    
    if 'current_stage' not in st.session_state:
        st.session_state.current_stage = None
    
    if 'progress_logs' not in st.session_state:
        st.session_state.progress_logs = []

init_session_state()


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    st.title("ğŸ¤– AI í…ŒìŠ¤íŠ¸ ìƒì„±ê¸°")
    st.markdown("### VCS ë³€ê²½ì‚¬í•­ìœ¼ë¡œë¶€í„° ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ìƒì„±")
    
    # ì‚¬ì´ë“œë°” ë©”ë‰´
    with st.sidebar:
        selected = option_menu(
            "ë©”ì¸ ë©”ë‰´",
            ["ì €ì¥ì†Œ ì„¤ì •", "ì»¤ë°‹ ì„ íƒ", "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", "ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸°"],
            icons=['folder', 'git', 'play-circle', 'download'],
            menu_icon="cast",
            default_index=0,
        )
    
    # í˜ì´ì§€ ë¼ìš°íŒ…
    if selected == "ì €ì¥ì†Œ ì„¤ì •":
        show_repository_setup()
    elif selected == "ì»¤ë°‹ ì„ íƒ":
        show_commit_selection()
    elif selected == "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰":
        show_pipeline_execution()
    elif selected == "ê²°ê³¼ ë° ë‚´ë³´ë‚´ê¸°":
        show_results_export()


def show_repository_setup():
    """ì €ì¥ì†Œ ì„¤ì • í˜ì´ì§€"""
    st.header("ğŸ“ ì €ì¥ì†Œ ì„¤ì •")
    
    # ì €ì¥ì†Œ íƒ€ì… ì„ íƒ
    repo_type = st.radio(
        "ì €ì¥ì†Œ íƒ€ì…",
        ["ë¡œì»¬ ì €ì¥ì†Œ", "ì›ê²© ì €ì¥ì†Œ"],
        horizontal=True
    )
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if repo_type == "ë¡œì»¬ ì €ì¥ì†Œ":
            show_local_repository_setup()
        else:
            show_remote_repository_setup()
    
    with col2:
        show_configuration_status()


def show_local_repository_setup():
    """ë¡œì»¬ ì €ì¥ì†Œ ì„¤ì •"""
    st.subheader("ğŸ–¥ï¸ ë¡œì»¬ Git ì €ì¥ì†Œ ì„¤ì •")
    
    # ì €ì¥ì†Œ ê²½ë¡œ ì…ë ¥
    repo_path = st.text_input(
        "ì €ì¥ì†Œ ê²½ë¡œ",
        value=st.session_state.get('repo_path', ''),
        help="ë¡œì»¬ Git ì €ì¥ì†Œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="/path/to/your/repository"
    )
    
    # ë¸Œëœì¹˜ ì„ íƒ
    branch = st.text_input(
        "ë¸Œëœì¹˜",
        value=st.session_state.get('branch', 'main'),
        help="ë¶„ì„í•  ë¸Œëœì¹˜ (ê¸°ë³¸ê°’: main)"
    )
    
    # í´ë” ì„ íƒ ë„ìš°ë¯¸
    st.markdown("ğŸ’¡ **ì•ˆë‚´**: ì ˆëŒ€ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ì˜ˆ: `/Users/username/projects/myrepo` ë˜ëŠ” `C:\\Users\\username\\projects\\myrepo`")
    
    # ì €ì¥ì†Œ ì—°ê²° ë²„íŠ¼
    if st.button("ğŸ”— ë¡œì»¬ ì €ì¥ì†Œ ì—°ê²°", type="primary"):
        if repo_path and Path(repo_path).exists():
            try:
                with st.spinner("ì €ì¥ì†Œ ì—°ê²° ë° Git ì„¤ì • í™•ì¸ ì¤‘..."):
                    # 1ë‹¨ê³„: Git ì„¤ì • í™•ì¸ì„ ìœ„í•œ ì„ì‹œ CommitSelector ìƒì„±
                    temp_selector = CommitSelector.__new__(CommitSelector)
                    temp_selector.repo_path = Path(repo_path)
                    temp_selector.branch = branch
                    temp_selector.repo = None  # GitPython ì´ˆê¸°í™”ëŠ” ë‚˜ì¤‘ì—
                    
                    # Git ì„¤ì • í™•ì¸
                    current_config = temp_selector._check_git_encoding_config()
                    required_config = {
                        'core.quotepath': 'false',
                        'i18n.logoutputencoding': 'utf-8',
                        'i18n.commitencoding': 'utf-8'
                    }
                    
                    changes_needed = []
                    for key, required_value in required_config.items():
                        if current_config.get(key) != required_value:
                            changes_needed.append({
                                'key': key,
                                'current': current_config.get(key, 'not set'),
                                'required': required_value,
                                'description': temp_selector._get_config_description(key)
                            })
                    
                    # Git ì„¤ì • ë³€ê²½ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ìì—ê²Œ í™•ì¸
                    auto_configure = True  # ê¸°ë³¸ê°’
                    if changes_needed:
                        st.session_state['git_config_changes'] = changes_needed
                        st.session_state['git_config_approved'] = None  # ì´ˆê¸°í™”
                        st.session_state['pending_repo_connection'] = {
                            'repo_path': repo_path,
                            'branch': branch,
                            'repo_type': 'local'
                        }
                        st.rerun()
                
                # ì‹¤ì œ CommitSelector ì´ˆê¸°í™” (ì„¤ì • ë³€ê²½ í›„)
                commit_selector = CommitSelector(repo_path, branch)
                st.session_state.commit_selector = commit_selector
                st.session_state.repo_path = repo_path
                st.session_state.repo_url = None  # ë¡œì»¬ì´ë¯€ë¡œ URL ì´ˆê¸°í™”
                st.session_state.branch = branch
                st.session_state.repo_type = "local"
                
                # PipelineOrchestrator ì´ˆê¸°í™”
                st.session_state.pipeline_orchestrator = PipelineOrchestrator(st.session_state.config)
                
                st.success("âœ… ë¡œì»¬ ì €ì¥ì†Œ ì—°ê²° ì„±ê³µ!")
                
                # ì €ì¥ì†Œ ì •ë³´ í‘œì‹œ
                with st.expander("ì €ì¥ì†Œ ì •ë³´", expanded=True):
                    repo_info = get_repository_info(commit_selector)
                    display_repository_info(repo_info)
                
            except Exception as e:
                st.error(f"âŒ ì—°ê²° ì‹¤íŒ¨: {e}")
                st.info("ìœ íš¨í•œ Git ì €ì¥ì†Œ ê²½ë¡œì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”")
        else:
            st.error("âŒ ì‹œìŠ¤í…œì— ì¡´ì¬í•˜ëŠ” ìœ íš¨í•œ ì €ì¥ì†Œ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    
    # Git ì„¤ì • ë³€ê²½ ëŒ€í™”ìƒì ì²˜ë¦¬
    if 'git_config_changes' in st.session_state and st.session_state['git_config_changes']:
        st.markdown("---")
        handle_git_config_dialog()


def show_remote_repository_setup():
    """ì›ê²© ì €ì¥ì†Œ ì„¤ì •"""
    st.subheader("ğŸŒ ì›ê²© Git ì €ì¥ì†Œ ì„¤ì •")
    
    # ì›ê²© ì €ì¥ì†Œ URL ì…ë ¥
    repo_url = st.text_input(
        "ì €ì¥ì†Œ URL",
        value=st.session_state.get('repo_url', ''),
        help="ì›ê²© Git ì €ì¥ì†Œ URLì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="https://github.com/username/repository.git"
    )
    
    # ë¸Œëœì¹˜ ì„ íƒ
    branch = st.text_input(
        "Branch",
        value=st.session_state.get('branch', 'main'),
        help="Branch to analyze (default: main)"
    )
    
    # ì¸ì¦ ì„¤ì •
    with st.expander("Authentication Settings (if required)"):
        auth_method = st.selectbox(
            "Authentication Method",
            ["None (Public Repository)", "Username/Password", "Personal Access Token"],
            help="Select authentication method for private repositories"
        )
        
        if auth_method == "Username/Password":
            username = st.text_input("Username")
            password = st.text_input("Password", type="password")
        elif auth_method == "Personal Access Token":
            token = st.text_input("Personal Access Token", type="password", 
                                help="GitHub Personal Access Token or GitLab Access Token")
    
    # URL í˜•ì‹ ë„ìš°ë¯¸
    st.markdown("""
    ğŸ’¡ **Supported URL formats**:
    - HTTPS: `https://github.com/user/repo.git`
    - SSH: `git@github.com:user/repo.git`  
    - GitLab: `https://gitlab.com/user/repo.git`
    - Azure DevOps: `https://dev.azure.com/org/project/_git/repo`
    """)
    
    # ì›ê²© ì €ì¥ì†Œ ì—°ê²° ë²„íŠ¼
    if st.button("ğŸŒ Connect to Remote Repository", type="primary"):
        if repo_url:
            try:
                with st.spinner("ğŸ”„ Cloning remote repository and checking Git configuration..."):
                    # 1ë‹¨ê³„: ì›ê²© ì €ì¥ì†Œ í´ë¡ 
                    from src.ai_test_generator.core.git_analyzer import GitAnalyzer
                    temp_path = GitAnalyzer.clone_remote_repo(repo_url, branch=branch)
                    
                    # 2ë‹¨ê³„: Git ì„¤ì • í™•ì¸ì„ ìœ„í•œ ì„ì‹œ CommitSelector ìƒì„±
                    temp_selector = CommitSelector.__new__(CommitSelector)
                    temp_selector.repo_path = Path(temp_path)
                    temp_selector.branch = branch
                    temp_selector.repo = None  # GitPython ì´ˆê¸°í™”ëŠ” ë‚˜ì¤‘ì—
                    
                    # Git ì„¤ì • í™•ì¸
                    current_config = temp_selector._check_git_encoding_config()
                    required_config = {
                        'core.quotepath': 'false',
                        'i18n.logoutputencoding': 'utf-8',
                        'i18n.commitencoding': 'utf-8'
                    }
                    
                    changes_needed = []
                    for key, required_value in required_config.items():
                        if current_config.get(key) != required_value:
                            changes_needed.append({
                                'key': key,
                                'current': current_config.get(key, 'not set'),
                                'required': required_value,
                                'description': temp_selector._get_config_description(key)
                            })
                    
                    # Git ì„¤ì • ë³€ê²½ì´ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ìì—ê²Œ í™•ì¸
                    if changes_needed:
                        st.session_state['git_config_changes'] = changes_needed
                        st.session_state['git_config_approved'] = None  # ì´ˆê¸°í™”
                        st.session_state['pending_repo_connection'] = {
                            'repo_path': temp_path,
                            'repo_url': repo_url,
                            'branch': branch,
                            'repo_type': 'remote'
                        }
                        st.rerun()
                
                # ì‹¤ì œ CommitSelector ì´ˆê¸°í™” (ì„¤ì • ë³€ê²½ í›„)
                commit_selector = CommitSelector(temp_path, branch)
                st.session_state.commit_selector = commit_selector
                st.session_state.repo_path = temp_path
                st.session_state.repo_url = repo_url
                st.session_state.branch = branch
                st.session_state.repo_type = "remote"
                
                # PipelineOrchestrator ì´ˆê¸°í™”
                st.session_state.pipeline_orchestrator = PipelineOrchestrator(st.session_state.config)
                
                st.success("âœ… Successfully connected to remote repository!")
                st.info(f"ğŸ“ Repository cloned to temporary location: {temp_path}")
                
                # ì €ì¥ì†Œ ì •ë³´ í‘œì‹œ
                with st.expander("Repository Information", expanded=True):
                    repo_info = get_repository_info(commit_selector)
                    display_repository_info(repo_info)
                
            except Exception as e:
                st.error(f"âŒ Failed to connect to remote repository: {e}")
                st.markdown("""
                **Possible issues:**
                - Repository URL is incorrect
                - Repository is private and requires authentication
                - Network connectivity issues
                - Git is not installed on the system
                """)
        else:
            st.error("âŒ Please provide a valid repository URL")
    
    # Git ì„¤ì • ë³€ê²½ ëŒ€í™”ìƒì ì²˜ë¦¬ (ì›ê²© ì €ì¥ì†Œë„ ë™ì¼í•˜ê²Œ)
    if 'git_config_changes' in st.session_state and st.session_state['git_config_changes']:
        st.markdown("---")
        handle_git_config_dialog()


@st.dialog("Git Configuration Required")
def git_config_modal():
    """Git ì„¤ì • ë³€ê²½ ëª¨ë‹¬ ëŒ€í™”ìƒì"""
    changes_needed = st.session_state['git_config_changes']
    
    st.markdown("### ğŸ”§ Git Configuration Optimization")
    
    st.markdown("""
    To properly handle non-ASCII characters (Korean, Chinese, etc.) in commit messages,
    the following Git repository settings need to be updated:
    """)
    
    # ë³€ê²½ì‚¬í•­ í‘œì‹œ
    for i, change in enumerate(changes_needed, 1):
        with st.expander(f"Setting {i}: {change['key']}", expanded=False):
            st.text(f"Description: {change['description']}")
            st.text(f"Current value: '{change['current']}'")
            st.text(f"Required value: '{change['required']}'")
    
    st.info("""
    â„¹ï¸ **Important Notes:**
    - These changes will be made to the LOCAL repository configuration only
    - Your global Git settings will not be affected
    - You can revert these changes later using: `git config --local --unset <key>`
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("âœ… Proceed with Changes", type="primary", key="proceed_git_config_modal"):
            # Git ì„¤ì • ë³€ê²½ ìŠ¹ì¸ ë° ëª¨ë‹¬ ë‹«ê¸°
            st.session_state.git_config_approved = True
            st.rerun()
    
    with col2:
        if st.button("âŒ Skip Configuration", key="skip_git_config_modal"):
            # Git ì„¤ì • ë³€ê²½ ì—†ì´ ì§„í–‰ ë° ëª¨ë‹¬ ë‹«ê¸°
            st.session_state.git_config_approved = False
            st.rerun()


def handle_git_config_dialog():
    """Git ì„¤ì • ë³€ê²½ ëŒ€í™”ìƒì ì²˜ë¦¬"""
    # ëª¨ë‹¬ì´ í•„ìš”í•œ ê²½ìš° í‘œì‹œ
    if 'git_config_changes' in st.session_state and st.session_state.get('git_config_approved') is None:
        git_config_modal()
    
    # ì‚¬ìš©ìê°€ ê²°ì •ì„ ë‚´ë¦° ê²½ìš° ì²˜ë¦¬
    if st.session_state.get('git_config_approved') is not None:
        auto_configure = st.session_state.git_config_approved
        complete_repository_connection(auto_configure)
        
        # ìƒíƒœ ì´ˆê¸°í™”
        del st.session_state.git_config_approved
        if 'git_config_changes' in st.session_state:
            del st.session_state.git_config_changes


def complete_repository_connection(auto_configure: bool):
    """ì €ì¥ì†Œ ì—°ê²° ì™„ë£Œ"""
    try:
        pending_connection = st.session_state.get('pending_repo_connection')
        if not pending_connection:
            st.error("No pending connection found")
            return
        
        repo_path = pending_connection['repo_path']
        branch = pending_connection['branch']
        repo_type = pending_connection['repo_type']
        
        with st.spinner("Finalizing repository connection..."):
            # CommitSelector ì´ˆê¸°í™” (Git ì„¤ì • ì ìš©)
            commit_selector = CommitSelector(repo_path, branch)
            if auto_configure:
                # ëª…ì‹œì ìœ¼ë¡œ Git ì„¤ì • ì ìš©
                changes_needed = st.session_state['git_config_changes']
                commit_selector._setup_git_encoding(auto_configure=True)
                st.success(f"âœ… Applied {len(changes_needed)} Git configuration changes")
            else:
                st.info("Git configuration optimization was skipped")
            
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.commit_selector = commit_selector
            st.session_state.repo_path = repo_path
            st.session_state.branch = branch
            st.session_state.repo_type = repo_type
            
            if repo_type == 'local':
                st.session_state.repo_url = None
            elif repo_type == 'remote':
                st.session_state.repo_url = pending_connection.get('repo_url')
            
            # PipelineOrchestrator ì´ˆê¸°í™”
            st.session_state.pipeline_orchestrator = PipelineOrchestrator(st.session_state.config)
            
            # ì •ë¦¬
            del st.session_state['git_config_changes']
            del st.session_state['pending_repo_connection']
            
            if repo_type == 'remote':
                st.success("âœ… Successfully connected to remote repository!")
                st.info(f"ğŸ“ Repository cloned to temporary location: {repo_path}")
            else:
                st.success("âœ… Successfully connected to local repository!")
            
            # ì €ì¥ì†Œ ì •ë³´ í‘œì‹œ
            with st.expander("Repository Information", expanded=True):
                repo_info = get_repository_info(commit_selector)
                display_repository_info(repo_info)
            
            st.rerun()
    
    except Exception as e:
        st.error(f"âŒ Failed to complete repository connection: {e}")
        # ì˜¤ë¥˜ ë°œìƒì‹œ ì„¸ì…˜ ì •ë¦¬
        for key in ['git_config_changes', 'pending_repo_connection']:
            if key in st.session_state:
                del st.session_state[key]


def show_configuration_status():
    """ì„¤ì • ìƒíƒœ í‘œì‹œ"""
    st.subheader("Configuration Status")
    
    # ì—°ê²° ìƒíƒœ í‘œì‹œ
    if st.session_state.commit_selector:
        st.success("ğŸŸ¢ Repository Connected")
        
        repo_type = st.session_state.get('repo_type', 'unknown')
        if repo_type == 'local':
            st.info(f"ğŸ“ Local Path: {st.session_state.repo_path}")
        elif repo_type == 'remote':
            st.info(f"ğŸŒ Remote URL: {st.session_state.repo_url}")
            st.info(f"ğŸ“ Local Cache: {st.session_state.repo_path}")
        
        st.info(f"ğŸŒ¿ Branch: {st.session_state.branch}")
        
        # ì €ì¥ì†Œ ê´€ë¦¬ ë²„íŠ¼ë“¤
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ”„ Change Repository"):
                # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                for key in ['commit_selector', 'repo_path', 'repo_url', 'branch', 'repo_type']:
                    if key in st.session_state:
                        del st.session_state[key]
                st.rerun()
        
        with col2:
            if st.button("ğŸ”§ Reset Git Config"):
                try:
                    if st.session_state.commit_selector.reset_git_encoding_config():
                        st.success("Git encoding configuration reset to defaults")
                    else:
                        st.error("Failed to reset Git configuration")
                except Exception as e:
                    st.error(f"Error resetting Git config: {e}")
    else:
        st.warning("ğŸŸ¡ Repository Not Connected")
    
    st.divider()
    
    # Azure OpenAI ì„¤ì • ìƒíƒœ
    config = st.session_state.config
    if config.azure_openai.api_key and config.azure_openai.endpoint:
        st.success("ğŸŸ¢ Azure OpenAI Configured")
    else:
        st.warning("ğŸŸ¡ Azure OpenAI Not Configured")
        with st.expander("Configure Azure OpenAI"):
            new_api_key = st.text_input("API Key", type="password", help="Enter your Azure OpenAI API key")
            new_endpoint = st.text_input("Endpoint", help="Enter your Azure OpenAI endpoint URL")
            
            if st.button("Save Azure OpenAI Settings"):
                if new_api_key and new_endpoint:
                    # í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì„¤ì •ì— ì €ì¥ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë³´ì•ˆì„ ê³ ë ¤í•´ì•¼ í•¨)
                    import os
                    os.environ['AZURE_OPENAI_API_KEY'] = new_api_key
                    os.environ['AZURE_OPENAI_ENDPOINT'] = new_endpoint
                    
                    # Config ì¬ë¡œë“œ
                    st.session_state.config = Config()
                    st.success("Azure OpenAI settings saved!")
                    st.rerun()
                else:
                    st.error("Please provide both API Key and Endpoint")
    
    # ì¶”ê°€ ì„¤ì • ì •ë³´
    with st.expander("System Information"):
        st.text(f"Python Path: {sys.path[0]}")
        st.text(f"Working Directory: {Path.cwd()}")
        if hasattr(st.session_state, 'config'):
            st.text(f"Output Directory: {st.session_state.config.app.output_directory}")
            st.text(f"Temp Directory: {st.session_state.config.app.temp_directory}")


def get_repository_info(commit_selector: CommitSelector) -> Dict[str, Any]:
    """ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ"""
    try:
        # ìµœê·¼ ì»¤ë°‹ ì •ë³´
        recent_commits = commit_selector.get_commit_list(max_commits=10)
        
        # ë¸Œëœì¹˜ ì •ë³´
        branches = commit_selector.get_branch_list()
        
        # ê¸°ë³¸ í†µê³„
        total_commits = len(commit_selector.get_commit_list(max_commits=1000))
        
        return {
            'total_commits': total_commits,
            'recent_commits': recent_commits,
            'branches': branches,
            'last_updated': datetime.now()
        }
    except Exception as e:
        logger.error(f"Failed to get repository info: {e}")
        return {}


def display_repository_info(repo_info: Dict[str, Any]):
    """ì €ì¥ì†Œ ì •ë³´ í‘œì‹œ"""
    if not repo_info:
        st.warning("Unable to load repository information")
        return
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Commits", repo_info.get('total_commits', 'N/A'))
    
    with col2:
        st.metric("Branches", len(repo_info.get('branches', [])))
    
    with col3:
        st.metric("Recent Activity", f"{len(repo_info.get('recent_commits', []))} commits")
    
    # ìµœê·¼ ì»¤ë°‹ë“¤ í‘œì‹œ
    if repo_info.get('recent_commits'):
        st.subheader("Recent Commits")
        commits_df = pd.DataFrame([
            {
                'Hash': commit.short_hash,
                'Message': commit.message[:50] + ('...' if len(commit.message) > 50 else ''),
                'Author': commit.author,
                'Date': commit.date.strftime('%Y-%m-%d %H:%M'),
                'Files': len(commit.files_changed),
                'Test Commit': 'ğŸ§ª' if commit.is_test_commit else ''
            }
            for commit in repo_info['recent_commits'][:5]
        ])
        st.dataframe(commits_df, use_container_width=True)


def show_commit_selection():
    """ì»¤ë°‹ ì„ íƒ í˜ì´ì§€"""
    st.header("ğŸ“ Commit Selection")
    
    if not st.session_state.commit_selector:
        st.warning("âš ï¸ Please connect to a repository first (Repository Setup)")
        return
    
    commit_selector = st.session_state.commit_selector
    
    # í•„í„° ì˜µì…˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        max_commits = st.slider("Max Commits to Show", 10, 200, 50)
        exclude_test_commits = st.checkbox("Exclude Test Commits", True)
    
    with col2:
        author_filter = st.text_input("Filter by Author", "")
        date_range = st.date_input(
            "Date Range",
            value=(datetime.now() - timedelta(days=30), datetime.now()),
            max_value=datetime.now()
        )
    
    with col3:
        search_query = st.text_input("Search in Messages", "")
        if st.button("ğŸ” Search Commits"):
            if search_query:
                search_results = commit_selector.search_commits(search_query, "message", max_commits)
                display_commit_list(search_results, "Search Results")
    
    # ì»¤ë°‹ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
    try:
        since = datetime.combine(date_range[0], datetime.min.time()) if len(date_range) > 0 else None
        until = datetime.combine(date_range[1], datetime.max.time()) if len(date_range) > 1 else None
        
        commits = commit_selector.get_commit_list(
            max_commits=max_commits,
            since=since,
            until=until,
            author=author_filter if author_filter else None,
            exclude_test_commits=exclude_test_commits
        )
        
        if commits:
            display_commit_selection_ui(commits, commit_selector)
        else:
            st.info("No commits found matching the criteria")
            
    except Exception as e:
        st.error(f"Failed to load commits: {e}")


def display_commit_selection_ui(commits: List[CommitInfo], commit_selector: CommitSelector):
    """ì»¤ë°‹ ì„ íƒ UI í‘œì‹œ"""
    st.subheader(f"Available Commits ({len(commits)})")
    
    # ì»¤ë°‹ ì„ íƒ ì²´í¬ë°•ìŠ¤
    selected_commits = []
    
    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œí•˜ë˜, ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€
    commit_data = []
    for i, commit in enumerate(commits):
        commit_data.append({
            'Select': False,
            'Hash': commit.short_hash,
            'Message': commit.message[:60] + ('...' if len(commit.message) > 60 else ''),
            'Author': commit.author.split()[0] if commit.author else '',  # ì´ë¦„ë§Œ
            'Date': commit.date.strftime('%m-%d %H:%M'),
            'Files': len(commit.files_changed),
            '+/-': f"+{commit.additions}/-{commit.deletions}",
            'Test': 'ğŸ§ª' if commit.is_test_commit else '',
            'commit_obj': commit  # ì‹¤ì œ ì»¤ë°‹ ê°ì²´ëŠ” ìˆ¨ê¹€
        })
    
    # ìƒí˜¸ì‘ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”
    with st.form("commit_selection_form"):
        st.markdown("Select commits to analyze:")
        
        # ì»¤ë°‹ë³„ ì²´í¬ë°•ìŠ¤
        commit_checkboxes = {}
        for i, commit in enumerate(commits):
            col1, col2, col3, col4, col5 = st.columns([0.5, 1.5, 3, 1.5, 1])
            
            with col1:
                is_selected = st.checkbox("", key=f"commit_{i}")
                commit_checkboxes[commit.hash] = is_selected
            
            with col2:
                st.code(commit.short_hash)
            
            with col3:
                st.text(commit.message[:50] + ('...' if len(commit.message) > 50 else ''))
            
            with col4:
                st.text(f"{commit.author.split()[0] if commit.author else ''}")
            
            with col5:
                st.text(commit.date.strftime('%m-%d'))
                if commit.is_test_commit:
                    st.text("ğŸ§ª")
            
            # ì»¤ë°‹ ìƒì„¸ ì •ë³´ (í™•ì¥ ê°€ëŠ¥)
            with st.expander(f"Details: {commit.short_hash}", expanded=False):
                show_commit_details(commit, commit_selector)
        
        # ì•¡ì…˜ ì„ íƒ
        action = st.selectbox(
            "Action:",
            ["Select Action", "Select All", "Clear All", "Analyze Selected"],
            help="Choose what to do with the commit selection"
        )
        
        # ë‹¨ì¼ ì œì¶œ ë²„íŠ¼
        submit = st.form_submit_button("Execute Action", type="primary")
        
        # ì„ íƒëœ ì»¤ë°‹ë“¤ ì²˜ë¦¬
        if submit and action != "Select Action":
            if action == "Select All":
                selected_commits = [commit.hash for commit in commits]
                st.success(f"âœ… Selected all {len(selected_commits)} commits")
            elif action == "Clear All":
                selected_commits = []
                st.info("ğŸ”„ Cleared all selections")
            else:  # Analyze Selected
                selected_commits = [commit_hash for commit_hash, is_selected in commit_checkboxes.items() if is_selected]
            
            st.session_state.selected_commits = selected_commits
            
            if action == "Analyze Selected" and selected_commits:
                # ì„ íƒëœ ì»¤ë°‹ë“¤ì˜ í†µí•© ë³€ê²½ì‚¬í•­ ê³„ì‚°
                try:
                    combined_changes = commit_selector.calculate_combined_changes(selected_commits)
                    
                    # íŒŒì´í”„ë¼ì¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                    st.session_state.pipeline_context = create_pipeline_context(
                        st.session_state.config,
                        st.session_state.repo_path,
                        selected_commits,
                        combined_changes
                    )
                    
                    st.success(f"âœ… Selected {len(selected_commits)} commits for analysis")
                    
                    # í†µí•© ë³€ê²½ì‚¬í•­ ë¯¸ë¦¬ë³´ê¸°
                    show_combined_changes_preview(combined_changes)
                    
                    # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ì•ˆë‚´
                    st.info("ğŸ“ Go to **Pipeline Execution** to start the test generation process")
                    
                except Exception as e:
                    st.error(f"âŒ Failed to analyze selected commits: {e}")
    
    # í˜„ì¬ ì„ íƒëœ ì»¤ë°‹ë“¤ í‘œì‹œ
    if st.session_state.selected_commits:
        with st.sidebar:
            st.subheader("Selected Commits")
            for commit_hash in st.session_state.selected_commits:
                commit = next((c for c in commits if c.hash == commit_hash), None)
                if commit:
                    st.text(f"â€¢ {commit.short_hash}: {commit.message[:30]}...")


def show_commit_details(commit: CommitInfo, commit_selector: CommitSelector):
    """ì»¤ë°‹ ìƒì„¸ ì •ë³´ í‘œì‹œ"""
    col1, col2 = st.columns(2)
    
    with col1:
        st.text(f"Hash: {commit.hash}")
        st.text(f"Author: {commit.author}")
        st.text(f"Date: {commit.date}")
        st.text(f"Changes: +{commit.additions}/-{commit.deletions}")
    
    with col2:
        st.text(f"Files changed: {len(commit.files_changed)}")
        if commit.is_test_commit:
            st.warning("ğŸ§ª Test-related commit")
    
    # ë³€ê²½ëœ íŒŒì¼ ëª©ë¡
    if commit.files_changed:
        st.text("Changed files:")
        for file_path in commit.files_changed[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            st.code(file_path, language="text")
        
        if len(commit.files_changed) > 10:
            st.text(f"... and {len(commit.files_changed) - 10} more files")
    
    # ì „ì²´ ì»¤ë°‹ ì •ë³´ ì¡°íšŒ (form ë‚´ë¶€ì—ì„œëŠ” ë²„íŠ¼ ëŒ€ì‹  ìë™ìœ¼ë¡œ í‘œì‹œ)
    try:
        full_details = commit_selector.get_commit_details(commit.hash)
        if full_details:
            with st.expander("ğŸ“‹ Full Commit Details", expanded=False):
                st.json(full_details, expanded=False)
    except Exception as e:
        st.text(f"Details unavailable: {e}")


def show_combined_changes_preview(combined_changes: Dict[str, Any]):
    """í†µí•© ë³€ê²½ì‚¬í•­ ë¯¸ë¦¬ë³´ê¸°"""
    st.subheader("ğŸ“Š Combined Changes Preview")
    
    summary = combined_changes.get('summary', {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Files Changed", summary.get('total_files', 0))
    with col2:
        st.metric("Lines Added", summary.get('total_additions', 0))
    with col3:
        st.metric("Lines Deleted", summary.get('total_deletions', 0))
    with col4:
        st.metric("Net Changes", summary.get('net_changes', 0))
    
    # íŒŒì¼ë³„ ë³€ê²½ì‚¬í•­ ì°¨íŠ¸
    files_changed = combined_changes.get('files_changed', [])
    if files_changed:
        # ê°€ì¥ ë§ì´ ë³€ê²½ëœ íŒŒì¼ë“¤ í‘œì‹œ (ìƒìœ„ 10ê°œ)
        sorted_files = sorted(files_changed, key=lambda f: f['additions'] + f['deletions'], reverse=True)
        top_files = sorted_files[:10]
        
        if top_files:
            chart_data = pd.DataFrame([
                {
                    'File': f['filename'].split('/')[-1],  # íŒŒì¼ëª…ë§Œ
                    'Additions': f['additions'],
                    'Deletions': f['deletions']
                }
                for f in top_files
            ])
            
            fig = px.bar(
                chart_data, 
                x=['Additions', 'Deletions'], 
                y='File',
                orientation='h',
                title="Top Changed Files",
                color_discrete_map={'Additions': 'green', 'Deletions': 'red'}
            )
            st.plotly_chart(fig, use_container_width=True)


def create_pipeline_context(
    config: Config,
    repo_path: str,
    selected_commits: List[str],
    combined_changes: Dict[str, Any]
) -> PipelineContext:
    """íŒŒì´í”„ë¼ì¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    context = PipelineContext(
        config=config,
        repo_path=repo_path,
        selected_commits=selected_commits,
        combined_changes=combined_changes,
        progress_callback=log_progress,
        user_confirmation_callback=request_user_confirmation
    )
    
    return context


def log_progress(stage: str, progress: float, message: str):
    """ì§„í–‰ìƒí™© ë¡œê·¸"""
    log_entry = {
        'timestamp': datetime.now(),
        'stage': stage,
        'progress': progress,
        'message': message
    }
    
    st.session_state.progress_logs.append(log_entry)
    st.session_state.current_stage = stage
    
    logger.info(f"[{stage}] {progress:.1%}: {message}")


def request_user_confirmation(title: str, data: Dict[str, Any]) -> bool:
    """ì‚¬ìš©ì í™•ì¸ ìš”ì²­ (Streamlitì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ True ë°˜í™˜)"""
    # Streamlit UIì—ì„œëŠ” ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©ì´ ì œí•œì ì´ë¯€ë¡œ ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¹ì¸
    return True


def show_pipeline_execution():
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í˜ì´ì§€"""
    st.header("âš™ï¸ Pipeline Execution")
    
    if not st.session_state.pipeline_context:
        st.warning("âš ï¸ Please select commits first (Commit Selection)")
        return
    
    context = st.session_state.pipeline_context
    orchestrator = st.session_state.pipeline_orchestrator
    
    # íŒŒì´í”„ë¼ì¸ ì„¤ì •
    st.subheader("Pipeline Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(f"ğŸ“ Repository: {context.repo_path}")
        st.info(f"ğŸ”„ Selected Commits: {len(context.selected_commits)}")
    
    with col2:
        # ì‹¤í–‰í•  ë‹¨ê³„ ì„ íƒ
        stages_to_run = st.multiselect(
            "Stages to Execute",
            options=[stage.value for stage in orchestrator.stage_order],
            default=[stage.value for stage in orchestrator.stage_order],
            help="Select which pipeline stages to run"
        )
        
        # ì‹¤í–‰ ëª¨ë“œ
        execution_mode = st.radio(
            "Execution Mode",
            ["Full Pipeline", "Stage by Stage"],
            help="Full Pipeline runs all stages at once, Stage by Stage allows step-by-step execution"
        )
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ Start Pipeline Execution", type="primary"):
        if stages_to_run:
            # ì„ íƒëœ ë‹¨ê³„ë“¤ ë³€í™˜
            selected_stages = [PipelineStage(stage) for stage in stages_to_run]
            
            if execution_mode == "Full Pipeline":
                asyncio.run(execute_full_pipeline(orchestrator, context, selected_stages))
            else:
                st.session_state.pipeline_stages = selected_stages
                st.session_state.current_stage_index = 0
                st.info("Stage by Stage mode selected. Use the controls below to execute each stage.")
        else:
            st.error("Please select at least one stage to execute")
    
    # ë‹¨ê³„ë³„ ì‹¤í–‰ ëª¨ë“œ UI
    if execution_mode == "Stage by Stage" and hasattr(st.session_state, 'pipeline_stages'):
        show_stage_by_stage_execution(orchestrator, context)
    
    # ì§„í–‰ìƒí™© í‘œì‹œ
    show_progress_monitoring()
    
    # í˜„ì¬ ê²°ê³¼ í‘œì‹œ
    if st.session_state.pipeline_results:
        show_pipeline_results_preview()


async def execute_full_pipeline(orchestrator, context, stages):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    st.info("ğŸ”„ Executing pipeline...")
    
    # ì§„í–‰ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    
    try:
        # ë¹„ë™ê¸° ì‹¤í–‰
        results = await orchestrator.execute_pipeline(context, stages)
        st.session_state.pipeline_results = results
        
        # ì‹¤í–‰ ì™„ë£Œ ì•Œë¦¼
        success_count = sum(1 for result in results.values() if result.status == StageStatus.COMPLETED)
        total_count = len(results)
        
        if success_count == total_count:
            st.success(f"âœ… Pipeline completed successfully! ({success_count}/{total_count} stages)")
        else:
            st.warning(f"âš ï¸ Pipeline completed with issues ({success_count}/{total_count} stages successful)")
        
    except Exception as e:
        st.error(f"âŒ Pipeline execution failed: {e}")
        logger.error(f"Pipeline execution error: {e}")


def show_stage_by_stage_execution(orchestrator, context):
    """ë‹¨ê³„ë³„ ì‹¤í–‰ UI"""
    st.subheader("Stage by Stage Execution")
    
    stages = st.session_state.pipeline_stages
    current_index = st.session_state.get('current_stage_index', 0)
    
    if current_index < len(stages):
        current_stage = stages[current_index]
        
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            st.info(f"Stage {current_index + 1}/{len(stages)}")
        
        with col2:
            st.info(f"ğŸ”„ {current_stage.value.replace('_', ' ').title()}")
        
        with col3:
            if st.button("Execute Stage"):
                asyncio.run(execute_single_stage(orchestrator, context, current_stage))
                st.session_state.current_stage_index += 1
                st.rerun()
    else:
        st.success("âœ… All stages completed!")


async def execute_single_stage(orchestrator, context, stage):
    """ë‹¨ì¼ ìŠ¤í…Œì´ì§€ ì‹¤í–‰"""
    st.info(f"Executing {stage.value}...")
    
    try:
        result = await orchestrator.execute_single_stage(stage, context)
        
        if not st.session_state.pipeline_results:
            st.session_state.pipeline_results = {}
        
        st.session_state.pipeline_results[stage] = result
        
        if result.status == StageStatus.COMPLETED:
            st.success(f"âœ… {stage.value} completed successfully")
        elif result.status == StageStatus.FAILED:
            st.error(f"âŒ {stage.value} failed: {'; '.join(result.errors)}")
        
    except Exception as e:
        st.error(f"âŒ Failed to execute {stage.value}: {e}")


def show_progress_monitoring():
    """ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ í‘œì‹œ"""
    if st.session_state.progress_logs:
        st.subheader("ğŸ“ˆ Progress Monitoring")
        
        # ìµœê·¼ ë¡œê·¸ í‘œì‹œ
        recent_logs = st.session_state.progress_logs[-10:]  # ìµœê·¼ 10ê°œë§Œ
        
        for log in reversed(recent_logs):  # ìµœì‹  ìˆœìœ¼ë¡œ
            timestamp = log['timestamp'].strftime('%H:%M:%S')
            stage = log['stage']
            progress = log['progress']
            message = log['message']
            
            st.text(f"[{timestamp}] {stage}: {message} ({progress:.1%})")
        
        # ì „ì²´ ì§„í–‰ìƒí™© ë°”
        if st.session_state.current_stage:
            current_progress = recent_logs[-1]['progress'] if recent_logs else 0
            st.progress(current_progress, text=f"Current Stage: {st.session_state.current_stage}")


def show_pipeline_results_preview():
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°"""
    st.subheader("ğŸ“Š Pipeline Results Preview")
    
    results = st.session_state.pipeline_results
    
    # ë‹¨ê³„ë³„ ìƒíƒœ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    completed = sum(1 for r in results.values() if r.status == StageStatus.COMPLETED)
    failed = sum(1 for r in results.values() if r.status == StageStatus.FAILED)
    running = sum(1 for r in results.values() if r.status == StageStatus.RUNNING)
    pending = sum(1 for r in results.values() if r.status == StageStatus.PENDING)
    
    with col1:
        st.metric("Completed", completed, delta=None)
    with col2:
        st.metric("Failed", failed, delta=None)
    with col3:
        st.metric("Running", running, delta=None)
    with col4:
        st.metric("Pending", pending, delta=None)
    
    # ë‹¨ê³„ë³„ ìƒì„¸ ê²°ê³¼
    for stage, result in results.items():
        with st.expander(f"{stage.value.replace('_', ' ').title()} - {result.status.value}"):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.text(f"Status: {result.status.value}")
                if result.execution_time:
                    st.text(f"Execution Time: {result.execution_time:.2f}s")
                st.text(f"Errors: {len(result.errors)}")
                st.text(f"Warnings: {len(result.warnings)}")
            
            with col2:
                if result.data:
                    st.text("Generated Data:")
                    for key, value in result.data.items():
                        if isinstance(value, list):
                            st.text(f"  {key}: {len(value)} items")
                        elif isinstance(value, dict):
                            st.text(f"  {key}: {len(value)} keys")
                        else:
                            st.text(f"  {key}: {str(value)[:50]}...")
            
            # ì˜¤ë¥˜ ë° ê²½ê³  í‘œì‹œ
            if result.errors:
                st.error("Errors:")
                for error in result.errors:
                    st.text(f"  â€¢ {error}")
            
            if result.warnings:
                st.warning("Warnings:")
                for warning in result.warnings:
                    st.text(f"  â€¢ {warning}")


def show_results_export():
    """ê²°ê³¼ ë‚´ë³´ë‚´ê¸° í˜ì´ì§€"""
    st.header("ğŸ“¥ Results & Export")
    
    if not st.session_state.pipeline_results:
        st.warning("âš ï¸ No pipeline results available. Please execute the pipeline first.")
        return
    
    results = st.session_state.pipeline_results
    
    # ê²°ê³¼ ìš”ì•½
    st.subheader("ğŸ“Š Results Summary")
    
    # í†µê³„ ì¹´ë“œë“¤
    col1, col2, col3, col4 = st.columns(4)
    
    total_tests = 0
    total_scenarios = 0
    total_files = 0
    
    for result in results.values():
        if 'generated_tests' in result.data:
            total_tests += len(result.data['generated_tests'])
        if 'test_scenarios' in result.data:
            total_scenarios += len(result.data['test_scenarios'])
        if 'files_changed' in result.data:
            if isinstance(result.data['files_changed'], list):
                total_files += len(result.data['files_changed'])
            elif isinstance(result.data['files_changed'], dict):
                total_files += result.data['files_changed'].get('total_files', 0)
    
    with col1:
        st.metric("Generated Tests", total_tests)
    with col2:
        st.metric("Test Scenarios", total_scenarios)
    with col3:
        st.metric("Files Analyzed", total_files)
    with col4:
        st.metric("Pipeline Stages", len(results))
    
    # ìƒì„¸ ê²°ê³¼ í‘œì‹œ
    st.subheader("ğŸ“‹ Detailed Results")
    
    # íƒ­ìœ¼ë¡œ êµ¬ë¶„
    tabs = st.tabs(["Test Code", "Test Scenarios", "Analysis Results", "Export Options"])
    
    with tabs[0]:
        show_test_code_results(results)
    
    with tabs[1]:
        show_test_scenario_results(results)
    
    with tabs[2]:
        show_analysis_results(results)
    
    with tabs[3]:
        show_export_options(results)


def show_test_code_results(results):
    """í…ŒìŠ¤íŠ¸ ì½”ë“œ ê²°ê³¼ í‘œì‹œ"""
    test_code_result = results.get(PipelineStage.TEST_CODE_GENERATION)
    
    if not test_code_result or not test_code_result.data:
        st.info("No test code generated")
        return
    
    generated_tests = test_code_result.data.get('generated_tests', [])
    
    if generated_tests:
        st.write(f"Generated {len(generated_tests)} test cases:")
        
        for i, test in enumerate(generated_tests):
            with st.expander(f"Test {i+1}: {test.name if hasattr(test, 'name') else f'Test_{i+1}'}"):
                col1, col2 = st.columns(2)
                
                with col1:
                    if hasattr(test, 'description'):
                        st.text(f"Description: {test.description}")
                    if hasattr(test, 'test_type'):
                        st.text(f"Type: {test.test_type}")
                    if hasattr(test, 'priority'):
                        st.text(f"Priority: {test.priority}")
                
                with col2:
                    if hasattr(test, 'assertions'):
                        st.text(f"Assertions: {len(test.assertions)}")
                    if hasattr(test, 'dependencies'):
                        st.text(f"Dependencies: {len(test.dependencies)}")
                
                # í…ŒìŠ¤íŠ¸ ì½”ë“œ í‘œì‹œ
                if hasattr(test, 'code'):
                    st.code(test.code, language="python")


def show_test_scenario_results(results):
    """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ í‘œì‹œ"""
    scenario_result = results.get(PipelineStage.TEST_SCENARIO_GENERATION)
    
    if not scenario_result or not scenario_result.data:
        st.info("No test scenarios generated")
        return
    
    test_scenarios = scenario_result.data.get('test_scenarios', [])
    
    if test_scenarios:
        st.write(f"Generated {len(test_scenarios)} test scenarios:")
        
        # ì‹œë‚˜ë¦¬ì˜¤ í…Œì´ë¸”
        scenario_data = []
        for i, scenario in enumerate(test_scenarios):
            scenario_data.append({
                'ID': getattr(scenario, 'scenario_id', f'S{i+1}'),
                'Feature': getattr(scenario, 'feature', 'N/A'),
                'Description': getattr(scenario, 'description', '')[:50] + '...',
                'Priority': getattr(scenario, 'priority', 'Medium'),
                'Type': getattr(scenario, 'test_type', 'Functional'),
                'Steps': len(getattr(scenario, 'test_steps', []))
            })
        
        scenario_df = pd.DataFrame(scenario_data)
        st.dataframe(scenario_df, use_container_width=True)
        
        # ê°œë³„ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„¸ë³´ê¸°
        selected_scenario = st.selectbox(
            "Select scenario for details:",
            options=range(len(test_scenarios)),
            format_func=lambda x: f"{scenario_data[x]['ID']}: {scenario_data[x]['Feature']}"
        )
        
        if selected_scenario is not None:
            scenario = test_scenarios[selected_scenario]
            
            st.subheader(f"Scenario Details: {getattr(scenario, 'scenario_id', 'N/A')}")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.text(f"Feature: {getattr(scenario, 'feature', 'N/A')}")
                st.text(f"Priority: {getattr(scenario, 'priority', 'Medium')}")
                st.text(f"Type: {getattr(scenario, 'test_type', 'Functional')}")
            
            with col2:
                st.text(f"Preconditions: {len(getattr(scenario, 'preconditions', []))}")
                st.text(f"Test Steps: {len(getattr(scenario, 'test_steps', []))}")
                st.text(f"Expected Results: {len(getattr(scenario, 'expected_results', []))}")
            
            # ìƒì„¸ ë‚´ìš©
            if hasattr(scenario, 'description'):
                st.text(f"Description: {scenario.description}")
            
            if hasattr(scenario, 'test_steps') and scenario.test_steps:
                st.subheader("Test Steps:")
                for i, step in enumerate(scenario.test_steps):
                    st.text(f"{i+1}. {step}")


def show_analysis_results(results):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    vcs_result = results.get(PipelineStage.VCS_ANALYSIS)
    
    if not vcs_result or not vcs_result.data:
        st.info("No analysis results available")
        return
    
    # VCS ë¶„ì„ ê²°ê³¼
    st.subheader("VCS Analysis Results")
    
    combined_analysis = vcs_result.data.get('combined_analysis')
    if combined_analysis:
        summary = combined_analysis.get('summary', {})
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Files Changed", summary.get('total_files', 0))
        with col2:
            st.metric("Lines Added", summary.get('total_additions', 0))
        with col3:
            st.metric("Lines Deleted", summary.get('total_deletions', 0))
        
        # íŒŒì¼ë³„ ë³€ê²½ì‚¬í•­
        files_changed = combined_analysis.get('files_changed', [])
        if files_changed:
            st.subheader("Changed Files")
            
            file_data = []
            for file_info in files_changed[:20]:  # ìƒìœ„ 20ê°œë§Œ í‘œì‹œ
                file_data.append({
                    'File': file_info.get('filename', '').split('/')[-1],
                    'Full Path': file_info.get('filename', ''),
                    'Additions': file_info.get('additions', 0),
                    'Deletions': file_info.get('deletions', 0),
                    'Status': file_info.get('status', 'M')
                })
            
            file_df = pd.DataFrame(file_data)
            st.dataframe(file_df, use_container_width=True)
    
    # ì „ëµ ë¶„ì„ ê²°ê³¼
    strategy_result = results.get(PipelineStage.TEST_STRATEGY)
    if strategy_result and strategy_result.data:
        st.subheader("Test Strategy Analysis")
        
        strategies = strategy_result.data.get('test_strategies', [])
        if strategies:
            for i, strategy in enumerate(strategies):
                st.text(f"Strategy {i+1}: {strategy}")


def show_export_options(results):
    """ë‚´ë³´ë‚´ê¸° ì˜µì…˜ í‘œì‹œ"""
    st.subheader("Export Options")
    
    # ë‚´ë³´ë‚´ê¸° í˜•ì‹ ì„ íƒ
    export_formats = st.multiselect(
        "Select Export Formats:",
        ["JSON", "Excel", "Markdown Report", "Test Code Files"],
        default=["JSON", "Excel"]
    )
    
    # ë‚´ë³´ë‚´ê¸° ì„¤ì •
    col1, col2 = st.columns(2)
    
    with col1:
        include_raw_data = st.checkbox("Include Raw Data", True)
        include_metadata = st.checkbox("Include Metadata", True)
    
    with col2:
        compress_output = st.checkbox("Compress Output", False)
        timestamp_filename = st.checkbox("Add Timestamp to Filename", True)
    
    # ë‚´ë³´ë‚´ê¸° ì‹¤í–‰
    if st.button("ğŸ“¥ Export Results", type="primary"):
        try:
            export_files = export_results(
                results,
                export_formats,
                include_raw_data,
                include_metadata,
                compress_output,
                timestamp_filename
            )
            
            st.success(f"âœ… Exported {len(export_files)} files successfully!")
            
            # ë‹¤ìš´ë¡œë“œ ë§í¬ ì œê³µ
            for file_path in export_files:
                with open(file_path, 'rb') as f:
                    st.download_button(
                        label=f"Download {Path(file_path).name}",
                        data=f.read(),
                        file_name=Path(file_path).name,
                        mime='application/octet-stream'
                    )
                    
        except Exception as e:
            st.error(f"âŒ Export failed: {e}")


def export_results(
    results,
    formats,
    include_raw_data,
    include_metadata,
    compress_output,
    timestamp_filename
):
    """ê²°ê³¼ ë‚´ë³´ë‚´ê¸° ì‹¤í–‰"""
    export_files = []
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S') if timestamp_filename else ''
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    # JSON ë‚´ë³´ë‚´ê¸°
    if "JSON" in formats:
        json_data = {}
        
        for stage, result in results.items():
            json_data[stage.value] = {
                'status': result.status.value,
                'execution_time': result.execution_time,
                'errors': result.errors,
                'warnings': result.warnings
            }
            
            if include_raw_data:
                json_data[stage.value]['data'] = result.data
            
            if include_metadata:
                json_data[stage.value]['metadata'] = result.metadata
        
        json_filename = f"test_generation_results{'_' + timestamp if timestamp else ''}.json"
        json_path = output_dir / json_filename
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False, default=str)
        
        export_files.append(str(json_path))
    
    # Excel ë‚´ë³´ë‚´ê¸° (ê¸°ë³¸ì ì¸ ë°ì´í„°ë§Œ)
    if "Excel" in formats:
        excel_filename = f"test_results{'_' + timestamp if timestamp else ''}.xlsx"
        excel_path = output_dir / excel_filename
        
        # ê°„ë‹¨í•œ ê²°ê³¼ ìš”ì•½ì„ Excelë¡œ ë‚´ë³´ë‚´ê¸°
        summary_data = []
        for stage, result in results.items():
            summary_data.append({
                'Stage': stage.value,
                'Status': result.status.value,
                'Execution Time': result.execution_time,
                'Errors': len(result.errors),
                'Warnings': len(result.warnings),
                'Data Items': len(result.data) if result.data else 0
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_excel(excel_path, index=False, sheet_name='Pipeline Summary')
        
        export_files.append(str(excel_path))
    
    # Markdown ë¦¬í¬íŠ¸
    if "Markdown Report" in formats:
        md_filename = f"test_generation_report{'_' + timestamp if timestamp else ''}.md"
        md_path = output_dir / md_filename
        
        md_content = generate_markdown_report(results)
        
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        export_files.append(str(md_path))
    
    return export_files


def generate_markdown_report(results):
    """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
    md_content = f"""# AI Test Generation Report

Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Pipeline Summary

"""
    
    for stage, result in results.items():
        md_content += f"### {stage.value.replace('_', ' ').title()}\n\n"
        md_content += f"- **Status**: {result.status.value}\n"
        md_content += f"- **Execution Time**: {result.execution_time:.2f}s\n" if result.execution_time else "- **Execution Time**: N/A\n"
        md_content += f"- **Errors**: {len(result.errors)}\n"
        md_content += f"- **Warnings**: {len(result.warnings)}\n"
        
        if result.data:
            md_content += f"- **Generated Items**: {len(result.data)} data keys\n"
        
        if result.errors:
            md_content += "\n**Errors:**\n"
            for error in result.errors:
                md_content += f"- {error}\n"
        
        if result.warnings:
            md_content += "\n**Warnings:**\n"
            for warning in result.warnings:
                md_content += f"- {warning}\n"
        
        md_content += "\n"
    
    return md_content


if __name__ == "__main__":
    main()