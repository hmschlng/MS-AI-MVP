#!/usr/bin/env python3
"""
AI Test Generator - Project Runner

í”„ë¡œì íŠ¸ì˜ ë‹¤ì–‘í•œ ì‹¤í–‰ ì˜µì…˜ì„ ì œê³µí•˜ëŠ” í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import sys
import argparse
from pathlib import Path
from typing import Optional, List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# Legacy imports removed - now using Pipeline system only
from ai_test_generator.core.commit_selector import CommitSelector
from ai_test_generator.core.pipeline_stages import PipelineOrchestrator, PipelineContext, PipelineStage
from ai_test_generator.utils.config import Config
from ai_test_generator.utils.logger import setup_logger, get_logger


def setup_argument_parser() -> argparse.ArgumentParser:
    """ëª…ë ¹í–‰ ì¸ì íŒŒì„œ ì„¤ì •"""
    parser = argparse.ArgumentParser(
        description="AI Test Generator - Automated test generation from VCS changes",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Interactive commit selection (recommended)
  python run.py interactive ./my-repo --max-commits 20
  python run.py interactive https://github.com/user/repo.git --max-commits 20

  # Pipeline execution with specific commits
  python run.py pipeline ./my-repo --commits abc123 def456 789ghi
  python run.py pipeline https://github.com/user/repo.git --commits abc123 def456

  # Launch Streamlit web interface
  python run.py ui --port 8501

  # Quick Git analysis (auto-selects recent commits)
  python run.py git ./my-repo --max-commits 10

  # Quick remote Git analysis
  python run.py remote https://github.com/user/repo.git --max-commits 10

  # Run examples
  python run.py example local

  # Run tests
  python run.py test unit
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Simple Git analysis command (Pipeline-based)
    git_parser = subparsers.add_parser('git', help='Quick Git repository analysis (uses latest commits)')
    git_parser.add_argument('repo_path', help='Path to Git repository')
    git_parser.add_argument('--branch', help='Branch to analyze (default: current branch)')
    git_parser.add_argument('--max-commits', type=int, default=10, help='Maximum commits to analyze (default: 10)')
    
    # ìƒˆë¡œìš´ ëŒ€í™”í˜• Git ë¶„ì„ ëª…ë ¹
    interactive_parser = subparsers.add_parser('interactive', help='Interactive Git repository analysis')
    interactive_parser.add_argument('repo_source', help='Path to local Git repository or remote URL')
    interactive_parser.add_argument('--branch', help='Branch to analyze (default: current branch)')
    interactive_parser.add_argument('--max-commits', type=int, default=50, help='Maximum commits to show (default: 50)')
    interactive_parser.add_argument('--exclude-test-commits', action='store_true', default=True, help='Exclude test commits')
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ëª…ë ¹
    pipeline_parser = subparsers.add_parser('pipeline', help='Execute pipeline with selected commits')
    pipeline_parser.add_argument('repo_source', help='Path to local Git repository or remote URL')
    pipeline_parser.add_argument('--commits', nargs='+', required=True, help='Commit hashes to analyze')
    pipeline_parser.add_argument('--branch', help='Branch to analyze (default: current branch)')
    pipeline_parser.add_argument('--stages', nargs='+', choices=['vcs_analysis', 'test_strategy', 'test_code_generation', 'test_scenario_generation', 'review_generation'], help='Pipeline stages to run')
    
    # Streamlit UI ì‹œì‘ ëª…ë ¹
    ui_parser = subparsers.add_parser('ui', help='Launch Streamlit web interface')
    ui_parser.add_argument('--port', type=int, default=8501, help='Port for Streamlit app (default: 8501)')
    
    # Simple remote Git analysis command (Pipeline-based)  
    remote_parser = subparsers.add_parser('remote', help='Quick remote Git repository analysis')
    remote_parser.add_argument('remote_url', help='Remote repository URL')
    remote_parser.add_argument('--branch', help='Branch to analyze')
    remote_parser.add_argument('--max-commits', type=int, default=10, help='Maximum commits to analyze (default: 10)')
    
    # ì˜ˆì œ ì‹¤í–‰ ëª…ë ¹
    example_parser = subparsers.add_parser('example', help='Run example scenarios')
    example_parser.add_argument('example_type', 
                               choices=['local', 'remote', 'advanced', 'error', 'config', 'perf', 'all'],
                               help='Type of example to run')
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹
    test_parser = subparsers.add_parser('test', help='Run project tests')
    test_parser.add_argument('test_type', 
                            choices=['unit', 'integration', 'performance', 'error', 'all'],
                            nargs='?', default='all',
                            help='Type of tests to run (default: all)')
    
    # ê³µí†µ ì¸ì - gitê³¼ remoteë„ í¬í•¨í•˜ì—¬ Pipeline ê¸°ë°˜ìœ¼ë¡œ í†µì¼
    for p in [git_parser, remote_parser, interactive_parser, pipeline_parser]:
        p.add_argument('--output', help='Output directory (default: ./output)')
        p.add_argument('--project-name', help='Project name for reports')
        p.add_argument('--project-version', help='Project version')
        p.add_argument('--tester', help='Tester name')
        p.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                      default='INFO', help='Logging level (default: INFO)')
        p.add_argument('--log-file', help='Log file path')
        p.add_argument('--quiet', '-q', action='store_true', help='Quiet mode (minimal output)')
        p.add_argument('--verbose', '-v', action='store_true', help='Verbose mode (detailed output)')
    
    return parser


async def run_git_analysis(args) -> None:
    """Git ë¶„ì„ ì‹¤í–‰ (Pipeline ê¸°ë°˜)"""
    logger = get_logger()
    
    if not Path(args.repo_path).exists():
        print(f"âŒ Error: Repository path does not exist: {args.repo_path}")
        return
    
    try:
        if not args.quiet:
            print(f"ğŸ” Quick Git repository analysis: {args.repo_path}")
            print(f"   Branch: {args.branch or 'current'}")
            print(f"   Max commits: {args.max_commits}")
        
        # CommitSelectorë¥¼ í†µí•œ ìµœì‹  ì»¤ë°‹ ìë™ ì„ íƒ
        commit_selector = CommitSelector(args.repo_path, args.branch or "main")
        recent_commits = commit_selector.get_commit_list(
            max_commits=args.max_commits,
            exclude_test_commits=True
        )
        
        if not recent_commits:
            print("âŒ No commits found to analyze")
            return
        
        # ìµœì‹  ì»¤ë°‹ë“¤ì„ ìë™ ì„ íƒ
        selected_commit_hashes = [commit.hash for commit in recent_commits[:min(5, len(recent_commits))]]
        
        if not args.quiet:
            print(f"ğŸ“ Auto-selected {len(selected_commit_hashes)} recent commits for analysis")
        
        # Pipelineìœ¼ë¡œ ì²˜ë¦¬
        await run_pipeline_for_commits(args, selected_commit_hashes)
        
    except Exception as e:
        logger.error(f"Git analysis failed: {e}")
        print(f"âŒ Analysis failed: {e}")


async def run_remote_analysis(args) -> None:
    """ì›ê²© ì €ì¥ì†Œ ë¶„ì„ ì‹¤í–‰ (Pipeline ê¸°ë°˜)"""
    logger = get_logger()
    temp_path = None
    
    try:
        if not args.quiet:
            print(f"ğŸŒ Quick remote repository analysis: {args.remote_url}")
            print(f"   Branch: {args.branch or 'default'}")
            print(f"   Max commits: {args.max_commits}")
        
        # ì›ê²© ì €ì¥ì†Œ í´ë¡ 
        from ai_test_generator.core.git_analyzer import GitAnalyzer
        temp_path = GitAnalyzer.clone_remote_repo(args.remote_url, branch=args.branch)
        
        if not args.quiet:
            print(f"ğŸ“ Repository cloned to: {temp_path}")
        
        # CommitSelectorë¥¼ í†µí•œ ìµœì‹  ì»¤ë°‹ ìë™ ì„ íƒ
        commit_selector = CommitSelector(temp_path, args.branch or "main")
        recent_commits = commit_selector.get_commit_list(
            max_commits=args.max_commits,
            exclude_test_commits=True
        )
        
        if not recent_commits:
            print("âŒ No commits found to analyze")
            return
        
        # ìµœì‹  ì»¤ë°‹ë“¤ì„ ìë™ ì„ íƒ
        selected_commit_hashes = [commit.hash for commit in recent_commits[:min(5, len(recent_commits))]]
        
        if not args.quiet:
            print(f"ğŸ“ Auto-selected {len(selected_commit_hashes)} recent commits for analysis")
        
        # repo_pathë¥¼ ì„ì‹œ ê²½ë¡œë¡œ ì„¤ì •í•˜ì—¬ Pipeline ì²˜ë¦¬
        args.repo_path = temp_path
        await run_pipeline_for_commits(args, selected_commit_hashes)
        
    except Exception as e:
        logger.error(f"Remote analysis failed: {e}")
        print(f"âŒ Analysis failed: {e}")
    
    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
        if temp_path:
            try:
                import shutil
                if Path(temp_path).exists():
                    shutil.rmtree(temp_path)
                    if not args.quiet:
                        print(f"ğŸ§¹ Cleaned up temporary directory")
            except Exception as e:
                logger.warning(f"Failed to clean up temp directory: {e}")


async def run_examples(args) -> None:
    """ì˜ˆì œ ì‹¤í–‰"""
    try:
        from example import main as example_main
        
        # example.pyì˜ sys.argvë¥¼ ì„¤ì •
        original_argv = sys.argv
        sys.argv = ['example.py', args.example_type]
        
        await example_main()
        
        sys.argv = original_argv
        
    except ImportError:
        print("âŒ Error: example.py not found")
    except Exception as e:
        print(f"âŒ Example execution failed: {e}")


def is_remote_url(repo_source: str) -> bool:
    """ì €ì¥ì†Œ ê²½ë¡œê°€ ì›ê²© URLì¸ì§€ í™•ì¸"""
    return repo_source.startswith(('http://', 'https://', 'git@', 'ssh://'))


async def setup_repository_access(repo_source: str, branch: str = None) -> tuple[CommitSelector, str, bool]:
    """ì €ì¥ì†Œ ì ‘ê·¼ ì„¤ì • (ë¡œì»¬/ì›ê²© ìë™ íŒë³„)"""
    is_remote = is_remote_url(repo_source)
    temp_path = None
    
    if is_remote:
        print(f"ğŸŒ Cloning remote repository: {repo_source}")
        print("   This may take a few moments...")
        
        from ai_test_generator.core.git_analyzer import GitAnalyzer
        temp_path = GitAnalyzer.clone_remote_repo(repo_source, branch=branch)
        repo_path = temp_path
        print(f"âœ… Repository cloned to: {temp_path}")
    else:
        if not Path(repo_source).exists():
            raise ValueError(f"Repository path does not exist: {repo_source}")
        repo_path = repo_source
    
    commit_selector = CommitSelector(repo_path, branch or "main")
    return commit_selector, repo_path, is_remote


async def run_interactive_analysis(args) -> None:
    """ëŒ€í™”í˜• Git ë¶„ì„ ì‹¤í–‰"""
    logger = get_logger()
    
    try:
        # ì €ì¥ì†Œ ì„¤ì • (ë¡œì»¬/ì›ê²© ìë™ íŒë³„)
        commit_selector, repo_path, is_remote = await setup_repository_access(
            args.repo_source, args.branch
        )
        
        repo_display = args.repo_source if is_remote else repo_path
        print(f"ğŸ” Interactive analysis for: {repo_display}")
        print(f"   Type: {'Remote' if is_remote else 'Local'}")
        print(f"   Branch: {args.branch or 'current'}")
        print(f"   Max commits: {args.max_commits}")
        print()
        
        # ì»¤ë°‹ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
        commits = commit_selector.get_commit_list(
            max_commits=args.max_commits,
            exclude_test_commits=args.exclude_test_commits
        )
        
        if not commits:
            print("âŒ No commits found")
            return
        
        # ì»¤ë°‹ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        print("ğŸ“‹ Available commits:")
        print("-" * 100)
        print(f"{'No.':<4} {'Hash':<10} {'Message':<50} {'Author':<15} {'Date':<12} {'Files':<6}")
        print("-" * 100)
        
        for i, commit in enumerate(commits):
            message = commit.message[:47] + "..." if len(commit.message) > 50 else commit.message
            author = commit.author.split()[0] if commit.author else "Unknown"
            date_str = commit.date.strftime("%m-%d %H:%M")
            test_indicator = " ğŸ§ª" if commit.is_test_commit else ""
            
            print(f"{i+1:<4} {commit.short_hash:<10} {message:<50} {author:<15} {date_str:<12} {len(commit.files_changed):<6}{test_indicator}")
        
        print("-" * 100)
        print()
        
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        while True:
            selection = input("Select commits (e.g., 1,3,5 or 1-5 or 'all' or 'q' to quit): ").strip()
            
            if selection.lower() in ['q', 'quit', 'exit']:
                print("ğŸ‘‹ Goodbye!")
                return
            
            try:
                selected_indices = parse_selection(selection, len(commits))
                if not selected_indices:
                    print("âŒ Invalid selection. Please try again.")
                    continue
                
                selected_commits = [commits[i] for i in selected_indices]
                
                # ì„ íƒëœ ì»¤ë°‹ë“¤ í‘œì‹œ
                print(f"\nâœ… Selected {len(selected_commits)} commits:")
                for commit in selected_commits:
                    print(f"   â€¢ {commit.short_hash}: {commit.message[:50]}")
                
                # í™•ì¸ ë°›ê¸°
                confirm = input("\nProceed with analysis? (y/N): ").strip().lower()
                if confirm in ['y', 'yes']:
                    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (repo_pathë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸)
                    args.repo_path = repo_path
                    await run_pipeline_for_commits(args, [c.hash for c in selected_commits])
                    break
                else:
                    print("Operation cancelled.")
                    continue
                
            except ValueError as e:
                print(f"âŒ Invalid input: {e}")
                continue
    
    except Exception as e:
        logger.error(f"Interactive analysis failed: {e}")
        print(f"âŒ Analysis failed: {e}")
    
    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ (ì›ê²© ì €ì¥ì†Œì¸ ê²½ìš°)
        if 'is_remote' in locals() and is_remote and 'repo_path' in locals():
            try:
                import shutil
                if Path(repo_path).exists():
                    shutil.rmtree(repo_path)
                    print(f"ğŸ§¹ Cleaned up temporary directory: {repo_path}")
            except Exception as e:
                logger.warning(f"Failed to clean up temp directory: {e}")


def parse_selection(selection: str, max_count: int) -> List[int]:
    """ì‚¬ìš©ì ì„ íƒ ì…ë ¥ íŒŒì‹±"""
    if selection.lower() == 'all':
        return list(range(max_count))
    
    indices = []
    parts = selection.split(',')
    
    for part in parts:
        part = part.strip()
        if '-' in part:
            # ë²”ìœ„ ì„ íƒ (ì˜ˆ: 1-5)
            try:
                start, end = map(int, part.split('-'))
                start = max(1, start)
                end = min(max_count, end)
                indices.extend(range(start-1, end))
            except ValueError:
                raise ValueError(f"Invalid range: {part}")
        else:
            # ë‹¨ì¼ ì„ íƒ
            try:
                idx = int(part)
                if 1 <= idx <= max_count:
                    indices.append(idx - 1)
                else:
                    raise ValueError(f"Index {idx} out of range (1-{max_count})")
            except ValueError:
                raise ValueError(f"Invalid number: {part}")
    
    return sorted(list(set(indices)))


async def run_pipeline_for_commits(args, commit_hashes: List[str]) -> None:
    """ì„ íƒëœ ì»¤ë°‹ë“¤ì— ëŒ€í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    try:
        config = Config()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if args.output:
            import os
            os.environ['OUTPUT_DIRECTORY'] = args.output
        
        # í”„ë¡œì íŠ¸ ì •ë³´ êµ¬ì„±
        project_info = {}
        if args.project_name:
            project_info['project_name'] = args.project_name
        if args.project_version:
            project_info['version'] = args.project_version
        if args.tester:
            project_info['tester'] = args.tester
        
        # CommitSelectorë¡œ í†µí•© ë³€ê²½ì‚¬í•­ ê³„ì‚°
        commit_selector = CommitSelector(args.repo_path, args.branch or "main")
        combined_changes = commit_selector.calculate_combined_changes(commit_hashes)
        
        # íŒŒì´í”„ë¼ì¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = PipelineContext(
            config=config,
            repo_path=args.repo_path,
            selected_commits=commit_hashes,
            combined_changes=combined_changes,
            project_info=project_info or None,
            progress_callback=print_progress,
            user_confirmation_callback=lambda title, data: True
        )
        
        # íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™”
        orchestrator = PipelineOrchestrator(config)
        
        print(f"\nğŸš€ Starting pipeline for {len(commit_hashes)} commits...")
        print(f"   Combined changes: {combined_changes['summary']['total_files']} files, +{combined_changes['summary']['total_additions']}/-{combined_changes['summary']['total_deletions']}")
        print()
        
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        results = await orchestrator.execute_pipeline(context)
        
        # ê²°ê³¼ ì¶œë ¥
        await print_pipeline_results(results, args.quiet, args.verbose)
        
    except Exception as e:
        print(f"âŒ Pipeline execution failed: {e}")


def print_progress(stage: str, progress: float, message: str):
    """ì§„í–‰ìƒí™© ì¶œë ¥"""
    print(f"[{stage.upper()}] {progress:.1%}: {message}")


async def run_pipeline_command(args) -> None:
    """íŒŒì´í”„ë¼ì¸ ëª…ë ¹ ì‹¤í–‰"""
    logger = get_logger()
    
    try:
        # ì €ì¥ì†Œ ì„¤ì • (ë¡œì»¬/ì›ê²© ìë™ íŒë³„)
        commit_selector, repo_path, is_remote = await setup_repository_access(
            args.repo_source, args.branch
        )
        
        # ë‹¨ê³„ ì„ íƒ
        if args.stages:
            stages = [PipelineStage(stage) for stage in args.stages]
        else:
            stages = None  # ëª¨ë“  ë‹¨ê³„ ì‹¤í–‰
        
        repo_display = args.repo_source if is_remote else repo_path
        print(f"ğŸ”„ Running pipeline for: {repo_display}")
        print(f"   Type: {'Remote' if is_remote else 'Local'}")
        print(f"   Selected commits: {args.commits}")
        if stages:
            print(f"   Stages: {[stage.value for stage in stages]}")
        else:
            print("   Stages: All stages")
        
        # repo_pathë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
        args.repo_path = repo_path
        await run_pipeline_for_commits(args, args.commits)
        
    except Exception as e:
        logger.error(f"Pipeline command failed: {e}")
        print(f"âŒ Command failed: {e}")
    
    finally:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬ (ì›ê²© ì €ì¥ì†Œì¸ ê²½ìš°)
        if 'is_remote' in locals() and is_remote and 'repo_path' in locals():
            try:
                import shutil
                if Path(repo_path).exists():
                    shutil.rmtree(repo_path)
                    print(f"ğŸ§¹ Cleaned up temporary directory: {repo_path}")
            except Exception as e:
                logger.warning(f"Failed to clean up temp directory: {e}")


async def run_ui_command(args) -> None:
    """Streamlit UI ì‹œì‘"""
    try:
        import subprocess
        import os
        
        # streamlit_app.py ê²½ë¡œ í™•ì¸
        app_path = Path(__file__).parent / "streamlit_app.py"
        
        if not app_path.exists():
            print(f"âŒ Error: Streamlit app not found at {app_path}")
            return
        
        print(f"ğŸŒ Starting Streamlit UI on port {args.port}...")
        print(f"   App will be available at: http://localhost:{args.port}")
        print("   Press Ctrl+C to stop the server")
        
        # Streamlit ì‹¤í–‰
        cmd = [
            "streamlit", "run", str(app_path),
            "--server.port", str(args.port),
            "--server.headless", "false",
            "--browser.gatherUsageStats", "false"
        ]
        
        # UTF-8 í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        
        subprocess.run(cmd, env=env, check=True)
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Failed to start Streamlit: {e}")
        print("Make sure Streamlit is installed: pip install streamlit")
    except KeyboardInterrupt:
        print("\nğŸ‘‹ UI stopped by user")
    except Exception as e:
        print(f"âŒ UI command failed: {e}")


async def run_tests(args) -> None:
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    try:
        import pytest
        
        # pytest ì¸ì êµ¬ì„±
        pytest_args = [
            "tests/",
            "-v",
            "--tb=short"
        ]
        
        if args.test_type != 'all':
            pytest_args.extend(["-m", args.test_type])
        
        # pytest ì‹¤í–‰
        exit_code = pytest.main(pytest_args)
        
        if exit_code == 0:
            print("âœ… All tests passed!")
        else:
            print(f"âŒ Some tests failed (exit code: {exit_code})")
            
    except ImportError:
        print("âŒ Error: pytest not installed")
        print("Install with: pip install pytest")
    except Exception as e:
        print(f"âŒ Test execution failed: {e}")


async def print_pipeline_results(results: Dict, quiet: bool = False, verbose: bool = False) -> None:
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì¶œë ¥"""
    if not results:
        print("âŒ No results to display")
        return
    
    # í†µê³„ ê³„ì‚°
    completed_stages = sum(1 for r in results.values() if r.status.value == 'completed')
    failed_stages = sum(1 for r in results.values() if r.status.value == 'failed')
    total_stages = len(results)
    
    total_tests = 0
    total_scenarios = 0
    total_execution_time = 0
    all_errors = []
    all_warnings = []
    
    for result in results.values():
        if hasattr(result, 'execution_time') and result.execution_time:
            total_execution_time += result.execution_time
        if hasattr(result, 'errors'):
            all_errors.extend(result.errors)
        if hasattr(result, 'warnings'):
            all_warnings.extend(result.warnings)
        if hasattr(result, 'data') and result.data:
            if 'generated_tests' in result.data:
                total_tests += len(result.data['generated_tests'])
            if 'test_scenarios' in result.data:
                total_scenarios += len(result.data['test_scenarios'])
    
    if quiet:
        status = "âœ… Success" if failed_stages == 0 else f"âš ï¸ Partial ({failed_stages} failed)"
        print(f"{status} | Stages: {completed_stages}/{total_stages} | Tests: {total_tests} | Scenarios: {total_scenarios} | Time: {total_execution_time:.1f}s")
        return
    
    print("\n" + "="*60)
    print("ğŸ“Š PIPELINE EXECUTION RESULTS")
    print("="*60)
    
    # ì „ì²´ í†µê³„
    print(f"ğŸ”„ Pipeline Stages: {completed_stages}/{total_stages} completed")
    print(f"ğŸ§ª Generated Tests: {total_tests}")
    print(f"ğŸ“‹ Test Scenarios: {total_scenarios}")
    print(f"â±ï¸ Total Execution Time: {total_execution_time:.2f} seconds")
    
    if failed_stages == 0:
        print("âœ… Status: All stages completed successfully")
    else:
        print(f"âš ï¸ Status: {failed_stages} stage(s) failed")
    
    # ë‹¨ê³„ë³„ ìƒì„¸ ê²°ê³¼
    print(f"\nğŸ“ Stage Details:")
    print("-" * 60)
    
    stage_order = ['vcs_analysis', 'test_strategy', 'test_code_generation', 'test_scenario_generation', 'review_generation']
    
    for stage_name in stage_order:
        stage_enum = None
        for stage_key in results.keys():
            if stage_key.value == stage_name:
                stage_enum = stage_key
                break
        
        if stage_enum and stage_enum in results:
            result = results[stage_enum]
            status_icon = "âœ…" if result.status.value == 'completed' else "âŒ" if result.status.value == 'failed' else "â¸ï¸"
            stage_display = stage_name.replace('_', ' ').title()
            exec_time = f"{result.execution_time:.2f}s" if hasattr(result, 'execution_time') and result.execution_time else "N/A"
            
            print(f"{status_icon} {stage_display:<25} | Time: {exec_time:<8} | Status: {result.status.value}")
            
            if verbose and hasattr(result, 'data') and result.data:
                for key, value in result.data.items():
                    if isinstance(value, list):
                        print(f"     â””â”€ {key}: {len(value)} items")
                    elif isinstance(value, dict):
                        print(f"     â””â”€ {key}: {len(value)} keys")
        else:
            print(f"â¸ï¸ {stage_name.replace('_', ' ').title():<25} | Time: N/A      | Status: not executed")
    
    # ì—ëŸ¬ ë° ê²½ê³  í‘œì‹œ
    if all_errors:
        print(f"\nâŒ Errors ({len(all_errors)}):")
        for i, error in enumerate(all_errors[:5 if not verbose else None]):
            print(f"   {i+1}. {error}")
        if len(all_errors) > 5 and not verbose:
            print(f"   ... and {len(all_errors) - 5} more errors (use --verbose for full list)")
    
    if all_warnings:
        print(f"\nâš ï¸ Warnings ({len(all_warnings)}):")
        for i, warning in enumerate(all_warnings[:3 if not verbose else None]):
            print(f"   {i+1}. {warning}")
        if len(all_warnings) > 3 and not verbose:
            print(f"   ... and {len(all_warnings) - 3} more warnings (use --verbose for full list)")
    
    # ì„±ëŠ¥ ì§€í‘œ
    if total_stages > 0 and total_execution_time > 0:
        avg_time_per_stage = total_execution_time / completed_stages if completed_stages > 0 else 0
        print(f"\nğŸ“ˆ Performance:")
        print(f"   Average time per stage: {avg_time_per_stage:.2f}s")
        if total_tests > 0:
            avg_time_per_test = total_execution_time / total_tests
            print(f"   Average time per test: {avg_time_per_test:.2f}s")
    
    print("\n" + "="*60)


# Legacy print_results function removed - now using Pipeline system with print_pipeline_results


def print_usage_help():
    """ì‚¬ìš©ë²• ë„ì›€ë§"""
    print("""
ğŸ¤– AI Test Generator

A tool for generating automated tests from VCS (Version Control System) changes.
Supports both local repositories and remote Git repositories.

Quick Start:
  1. ğŸŒ Launch Web UI (Recommended):    python run.py ui
  2. ğŸ’¬ Interactive analysis:           python run.py interactive ./my-repo
                                        python run.py interactive https://github.com/user/repo.git
  3. âš¡ Direct pipeline execution:       python run.py pipeline ./my-repo --commits abc123 def456
  4. ğŸ“Š Quick Git analysis:             python run.py git ./my-repo

ğŸŒ Web Interface:
  - Full-featured web UI with commit selection
  - Real-time progress monitoring
  - Visual results and export options

ğŸ’¬ Interactive CLI:
  - Browse commits in terminal
  - Select specific commits for analysis
  - Step-by-step guidance

âš¡ Direct Pipeline:
  - Execute with specific commit hashes
  - Scriptable for automation
  - Customizable pipeline stages

For detailed help:
  python run.py --help
  python run.py interactive --help
  python run.py pipeline --help

Configuration:
  - Set environment variables in .env file
  - Required: Azure OpenAI credentials
  - Optional: Azure AI Search credentials for RAG
    """)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    if not args.command:
        print_usage_help()
        return
    
    # ë¡œê·¸ ì„¤ì •
    log_level = getattr(args, 'log_level', 'DEBUG')
    log_file = getattr(args, 'log_file', None)
    setup_logger(log_level, log_file)
    
    try:
        if args.command == 'git':
            await run_git_analysis(args)
        elif args.command == 'remote':
            await run_remote_analysis(args)
        elif args.command == 'interactive':
            await run_interactive_analysis(args)
        elif args.command == 'pipeline':
            await run_pipeline_command(args)
        elif args.command == 'ui':
            await run_ui_command(args)
        elif args.command == 'example':
            await run_examples(args)
        elif args.command == 'test':
            await run_tests(args)
        else:
            print(f"âŒ Unknown command: {args.command}")
            parser.print_help()
    
    except KeyboardInterrupt:
        print("\nâš ï¸ Operation cancelled by user")
    except Exception as e:
        logger = get_logger()
        logger.error(f"Unexpected error: {e}")
        print(f"âŒ Unexpected error: {e}")
        
        # ë””ë²„ê·¸ ì •ë³´ (verbose ëª¨ë“œì—ì„œë§Œ)
        if getattr(args, 'verbose', False):
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())