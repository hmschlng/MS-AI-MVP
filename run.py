#!/usr/bin/env python3
"""
AI Test Generator - Project Runner

í”„ë¡œì íŠ¸ì˜ ë‹¤ì–‘í•œ ì‹¤í–‰ ì˜µì…˜ì„ ì œê³µí•˜ëŠ” í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import sys
import argparse
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from ai_test_generator.main import generate_tests_from_git, generate_tests_from_remote_git
from ai_test_generator.utils.config import Config
from ai_test_generator.utils.logger import setup_logger, get_logger


def setup_argument_parser() -> argparse.ArgumentParser:
    """ëª…ë ¹í–‰ ì¸ì íŒŒì„œ ì„¤ì •"""
    parser = argparse.ArgumentParser(
        description="AI Test Generator - Automated test generation from VCS changes",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Local Git repository
  python run.py git ./my-repo --max-commits 5

  # Remote Git repository  
  python run.py remote https://github.com/user/repo.git --max-commits 3

  # With custom output directory
  python run.py git ./my-repo --output ./test-results --project-name "My Project"

  # Run examples
  python run.py example local

  # Run tests
  python run.py test unit
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Git ë¶„ì„ ëª…ë ¹
    git_parser = subparsers.add_parser('git', help='Analyze local Git repository')
    git_parser.add_argument('repo_path', help='Path to Git repository')
    git_parser.add_argument('--branch', help='Branch to analyze (default: current branch)')
    git_parser.add_argument('--start-commit', help='Start commit hash')
    git_parser.add_argument('--end-commit', help='End commit hash') 
    git_parser.add_argument('--max-commits', type=int, default=10, help='Maximum commits to analyze (default: 10)')
    
    # ì›ê²© Git ë¶„ì„ ëª…ë ¹
    remote_parser = subparsers.add_parser('remote', help='Analyze remote Git repository')
    remote_parser.add_argument('remote_url', help='Remote repository URL')
    remote_parser.add_argument('--branch', help='Branch to analyze')
    remote_parser.add_argument('--max-commits', type=int, default=10, help='Maximum commits to analyze (default: 10)')
    
    # ì˜ˆì œ ì‹¤í–‰ ëª…ë ¹
    example_parser = subparsers.add_parser('example', help='Run example scenarios')
    example_parser.add_argument('example_type', 
                               choices=['local', 'remote', 'advanced', 'error', 'config', 'perf', 'all'],
                               help='Type of example to run')
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹
    test_parser = subparsers.add_parser('test', help='Run project tests')
    test_parser.add_argument('test_type', 
                            choices=['unit', 'integration', 'performance', 'error', 'all'],
                            nargs='?', default='all',
                            help='Type of tests to run (default: all)')
    
    # ê³µí†µ ì¸ì
    for p in [git_parser, remote_parser]:
        p.add_argument('--output', help='Output directory (default: ./output)')
        p.add_argument('--project-name', help='Project name for reports')
        p.add_argument('--project-version', help='Project version')
        p.add_argument('--tester', help='Tester name')
        p.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                      default='INFO', help='Logging level (default: INFO)')
        p.add_argument('--log-file', help='Log file path')
        p.add_argument('--quiet', '-q', action='store_true', help='Quiet mode (minimal output)')
        p.add_argument('--verbose', '-v', action='store_true', help='Verbose mode (detailed output)')
    
    return parser


async def run_git_analysis(args) -> None:
    """Git ë¶„ì„ ì‹¤í–‰"""
    logger = get_logger()
    
    if not Path(args.repo_path).exists():
        print(f"âŒ Error: Repository path does not exist: {args.repo_path}")
        return
    
    # í”„ë¡œì íŠ¸ ì •ë³´ êµ¬ì„±
    project_info = {}
    if args.project_name:
        project_info['project_name'] = args.project_name
    if args.project_version:
        project_info['version'] = args.project_version
    if args.tester:
        project_info['tester'] = args.tester
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output:
        import os
        os.environ['OUTPUT_DIRECTORY'] = args.output
    
    try:
        if not args.quiet:
            print(f"ğŸ” Analyzing Git repository: {args.repo_path}")
            print(f"   Branch: {args.branch or 'current'}")
            print(f"   Max commits: {args.max_commits}")
            if project_info:
                print(f"   Project: {project_info.get('project_name', 'N/A')}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = await generate_tests_from_git(
            repo_path=args.repo_path,
            start_commit=args.start_commit,
            end_commit=args.end_commit,
            branch=args.branch,
            max_commits=args.max_commits,
            project_info=project_info or None
        )
        
        # ê²°ê³¼ ì¶œë ¥
        await print_results(result, args.quiet, args.verbose)
        
    except Exception as e:
        logger.error(f"Git analysis failed: {e}")
        print(f"âŒ Analysis failed: {e}")


async def run_remote_analysis(args) -> None:
    """ì›ê²© ì €ì¥ì†Œ ë¶„ì„ ì‹¤í–‰"""
    logger = get_logger()
    
    # í”„ë¡œì íŠ¸ ì •ë³´ êµ¬ì„±
    project_info = {}
    if args.project_name:
        project_info['project_name'] = args.project_name
    if args.project_version:
        project_info['version'] = args.project_version
    if args.tester:
        project_info['tester'] = args.tester
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output:
        import os
        os.environ['OUTPUT_DIRECTORY'] = args.output
    
    try:
        if not args.quiet:
            print(f"ğŸŒ Analyzing remote repository: {args.remote_url}")
            print(f"   Branch: {args.branch or 'default'}")
            print(f"   Max commits: {args.max_commits}")
            if project_info:
                print(f"   Project: {project_info.get('project_name', 'N/A')}")
        
        # ë¶„ì„ ì‹¤í–‰
        result = await generate_tests_from_remote_git(
            remote_url=args.remote_url,
            branch=args.branch,
            max_commits=args.max_commits,
            project_info=project_info or None
        )
        
        # ê²°ê³¼ ì¶œë ¥
        await print_results(result, args.quiet, args.verbose)
        
    except Exception as e:
        logger.error(f"Remote analysis failed: {e}")
        print(f"âŒ Analysis failed: {e}")


async def run_examples(args) -> None:
    """ì˜ˆì œ ì‹¤í–‰"""
    try:
        from example import main as example_main
        
        # example.pyì˜ sys.argvë¥¼ ì„¤ì •
        original_argv = sys.argv
        sys.argv = ['example.py', args.example_type]
        
        await example_main()
        
        sys.argv = original_argv
        
    except ImportError:
        print("âŒ Error: example.py not found")
    except Exception as e:
        print(f"âŒ Example execution failed: {e}")


async def run_tests(args) -> None:
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    try:
        import pytest
        
        # pytest ì¸ì êµ¬ì„±
        pytest_args = [
            "tests/",
            "-v",
            "--tb=short"
        ]
        
        if args.test_type != 'all':
            pytest_args.extend(["-m", args.test_type])
        
        # pytest ì‹¤í–‰
        exit_code = pytest.main(pytest_args)
        
        if exit_code == 0:
            print("âœ… All tests passed!")
        else:
            print(f"âŒ Some tests failed (exit code: {exit_code})")
            
    except ImportError:
        print("âŒ Error: pytest not installed")
        print("Install with: pip install pytest")
    except Exception as e:
        print(f"âŒ Test execution failed: {e}")


async def print_results(result, quiet: bool = False, verbose: bool = False) -> None:
    """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    summary = result.to_summary_dict()
    
    if quiet:
        # ê°„ë‹¨í•œ ìš”ì•½ë§Œ
        status = "âœ… Success" if summary['success'] else "âŒ Failed"
        print(f"{status} | Tests: {summary['total_tests_generated']} | Scenarios: {summary['total_scenarios_generated']} | Time: {summary['execution_time_seconds']:.1f}s")
        return
    
    print("\n" + "="*50)
    print("ğŸ“Š ANALYSIS RESULTS")
    print("="*50)
    
    # ê¸°ë³¸ í†µê³„
    print(f"ğŸ” Commits Analyzed: {summary['total_commits_analyzed']}")
    print(f"ğŸ“ Files Changed: {summary['total_files_changed']}")
    print(f"ğŸ§ª Tests Generated: {summary['total_tests_generated']}")
    print(f"ğŸ“‹ Scenarios Generated: {summary['total_scenarios_generated']}")
    print(f"â±ï¸ Execution Time: {summary['execution_time_seconds']:.2f} seconds")
    print(f"âœ… Status: {'Success' if summary['success'] else 'Failed'}")
    
    # ì¶œë ¥ íŒŒì¼
    if summary['output_files']:
        print(f"\nğŸ“ Generated Files:")
        for file_type, file_path in summary['output_files'].items():
            file_size = ""
            if Path(file_path).exists():
                size_bytes = Path(file_path).stat().st_size
                if size_bytes > 1024*1024:
                    file_size = f" ({size_bytes/(1024*1024):.1f} MB)"
                elif size_bytes > 1024:
                    file_size = f" ({size_bytes/1024:.1f} KB)"
                else:
                    file_size = f" ({size_bytes} bytes)"
            
            print(f"   ğŸ“„ {file_type.title()}: {Path(file_path).name}{file_size}")
    
    # ì—ëŸ¬ ë° ê²½ê³ 
    if summary['errors']:
        print(f"\nâŒ Errors ({len(summary['errors'])}):")
        for error in summary['errors'][:5 if not verbose else None]:
            print(f"   â€¢ {error}")
        if len(summary['errors']) > 5 and not verbose:
            print(f"   â€¢ ... and {len(summary['errors']) - 5} more errors")
    
    if summary['warnings']:
        print(f"\nâš ï¸ Warnings ({len(summary['warnings'])}):")
        for warning in summary['warnings'][:3 if not verbose else None]:
            print(f"   â€¢ {warning}")
        if len(summary['warnings']) > 3 and not verbose:
            print(f"   â€¢ ... and {len(summary['warnings']) - 3} more warnings")
    
    # ìƒì„¸ ì •ë³´ (verbose ëª¨ë“œ)
    if verbose and result.commit_analyses:
        print(f"\nğŸ” Detailed Commit Analysis:")
        for i, analysis in enumerate(result.commit_analyses[:5], 1):
            print(f"\n   Commit {i}: {analysis.commit_hash[:8]}")
            print(f"   Author: {analysis.author}")
            print(f"   Date: {analysis.commit_date.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"   Message: {analysis.message[:50]}{'...' if len(analysis.message) > 50 else ''}")
            print(f"   Files: {len(analysis.files_changed)} changed (+{analysis.total_additions}/-{analysis.total_deletions})")
    
    # ì„±ëŠ¥ ì§€í‘œ
    if summary['total_commits_analyzed'] > 0:
        avg_time = summary['execution_time_seconds'] / summary['total_commits_analyzed']
        print(f"\nğŸ“ˆ Performance Metrics:")
        print(f"   Average time per commit: {avg_time:.2f}s")
        
        if summary['total_tests_generated'] > 0:
            avg_test_time = summary['execution_time_seconds'] / summary['total_tests_generated']
            print(f"   Average time per test: {avg_test_time:.2f}s")
    
    print("\n" + "="*50)


def print_usage_help():
    """ì‚¬ìš©ë²• ë„ì›€ë§"""
    print("""
ğŸ¤– AI Test Generator

A tool for generating automated tests from VCS (Version Control System) changes.

Quick Start:
  1. Analyze local Git repo:     python run.py git ./my-repo
  2. Analyze remote Git repo:    python run.py remote https://github.com/user/repo.git
  3. Run examples:               python run.py example local
  4. Run tests:                  python run.py test unit

For detailed help:
  python run.py --help
  python run.py git --help
  python run.py remote --help

Configuration:
  - Set environment variables in .env file
  - Required: Azure OpenAI credentials
  - Optional: Azure AI Search credentials for RAG
    """)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = setup_argument_parser()
    args = parser.parse_args()
    
    if not args.command:
        print_usage_help()
        return
    
    # ë¡œê·¸ ì„¤ì •
    log_level = getattr(args, 'log_level', 'INFO')
    log_file = getattr(args, 'log_file', None)
    setup_logger(log_level, log_file)
    
    try:
        if args.command == 'git':
            await run_git_analysis(args)
        elif args.command == 'remote':
            await run_remote_analysis(args)
        elif args.command == 'example':
            await run_examples(args)
        elif args.command == 'test':
            await run_tests(args)
        else:
            print(f"âŒ Unknown command: {args.command}")
            parser.print_help()
    
    except KeyboardInterrupt:
        print("\nâš ï¸ Operation cancelled by user")
    except Exception as e:
        logger = get_logger()
        logger.error(f"Unexpected error: {e}")
        print(f"âŒ Unexpected error: {e}")
        
        # ë””ë²„ê·¸ ì •ë³´ (verbose ëª¨ë“œì—ì„œë§Œ)
        if getattr(args, 'verbose', False):
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())